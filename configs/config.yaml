project_name: "RL-Portfolio-Management_IMPROVEMENTS"
epochs: 25
time_window: 30
rl_strats: ["PPOLSTM", "TD3"]
baseline: ["RANDOM"]
active_index: "dow"
varied_base_seeds:
  - 1
  - 3
  - 5
  - 7
  - 9
normalise_data: false
wandb_state: "disabled"
source_folder: "main"

env:
  tickers:
    dow:
      - MMM
      - AXP
      - AAPL
      - BA
      - CAT
      - CVX
      - CSCO
      - KO
      - NVDA
      - XOM
      - GS
      - HD
      - INTC
      - IBM
      - JNJ
      - JPM
      - MCD
      - MRK
      - MSFT
      - NKE
      - PFE
      - PG
      - RTX
      - TRV
      - UNH
      - VZ
      - V
      - WBA
      - WMT
      - DIS
  sse50:
    - "600690.SS"
    - "688012.SS"
    - "600309.SS"
    - "601601.SS"
    - "600031.SS"
    - "601398.SS"
    - "688256.SS"
    - "600028.SS"
    - "600519.SS"
    - "603993.SS"
    - "601668.SS"
    - "600809.SS"
    - "601166.SS"
    - "601128.SS"
    - "601899.SS"
    - "601857.SS"
    - "688041.SS"
    - "600887.SS"
    - "601988.SS"
    - "601328.SS"
    - "603501.SS"
    - "601658.SS"
    - "601212.SS"
    - "688008.SS"
    - "601919.SS"
    - "601088.SS"
    - "688111.SS"
    - "600900.SS"
    - "601318.SS"
    - "601728.SS"
  ftse100:
    - "RMV.L"
    - "IMI.L"
    - "ICG.L"
    - "PRU.L"
    - "AAL.L"
    - "KGF.L"
    - "DGE.L"
    - "PCT.L"
    - "FRES.L"
    - "UTG.L"
    - "SDR.L"
    - "WTB.L"
    - "HSX.L"
    - "LMP.L"
    - "VOD.L"
    - "HSBA.L"
    - "SGRO.L"
    - "IMB.L"
    - "MRO.L"
    - "BA.L"
    - "CNA.L"
    - "AV.L"
    - "MNG.L"
    - "BARC.L"
    - "BEZ.L"
    - "PHNX.L"
    - "AHT.L"
    - "BP.L"
    - "ANTO.L"
    - "RTO.L"

  comparisonStrategies:
    - "dow"
    - "sse50"
  redownload: True
  start_date: "2009-01-01"
  period: "1D"
  base_seed: 9
  transaction_cost: 0.0002
  start_cash: 10000
  perturbation_noise: 0.002

agent:
  gamma: 0.99
  reward_function: "Standard Logarithmic Returns"
  actor_critic_hidden_state_size: 512
  ppo:
    gae_lambda: 0.98
    clip_param: 0.2
    batch_size: 24
    learning_rate: 0.0003
    fc1_n: 128
    fc2_n: 128
    feature_output_size: 128
    epochs: 1
    entropy_coef: 0.01
    actor_noise: 0
    norm_advantages: false
    use_entropy: false
    use_dirichlet: true
    log_concentration: false
    use_normals: false # likely requires softmax; dividing may not work for short selling
    learning_frequency: 24
    strategy: "PPOLSTM"
  td3:
    alpha: 0.001
    beta: 0.001
    tau: 0.005
    batch_size: 100
    fc1_n: 512
    fc2_n: 384
    actor_noise: 0.01
    number_of_updates: 2
    target_noise: 0.01
    strategy: "TD3"

feature_extractors:
  lstm:
    default_hidden_size: 128
    return_hidden_state: True

hyperparameters:
  feature_output_sizes:
    - 32
    - 64
    - 128
    - 256
    - 512
  learning_rates:
    - 0.0001
    - 0.0003
    - 0.0005
    - 0.0007

evaluation:
  log_observations: false
  log_input_data: false

#argparse or something?
experiments:
  _common: &defaults
    dataType: "validation"
    benchmark: false
    comparisonStrat: null
    use_noise_eval: false
    for_learning_curve: false

  data_normalisation:
    <<: *defaults

  noise_testing:
    <<: *defaults

  hyperparameter_tuning:
    <<: *defaults

  reward_testing:
    dataType: "testing"
    benchmark: null
    comparisonStrat: null
    use_noise_eval: false #possible comparison with perturbed?
    for_learning_curve: True
    source_folder: "tests" #change this back brev

  random:
    <<: *defaults
    benchmark: true
    use_noise_eval: true

  nonRLComparisonStrategies:
    <<: *defaults
    dataType: "testing"

test:
  learning_curve_frequency: 500
