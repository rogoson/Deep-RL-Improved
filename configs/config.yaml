project_name: "RL-Portfolio-Management_IMPROVEMENTS"
epochs: 15
time_window: 30
rl_strats: ["PPOLSTM", "TD3"]
baseline: ["RANDOM"]
varied_base_seeds:
  - 1
  - 3
  - 5
  - 7
  - 9
normalise_data: false
wandb_state: "online"
source_folder: "main"

env:
  tickers:
    dow:
      - MMM
      - AXP
      - AAPL
      - BA
      - CAT
      - CVX
      - CSCO
      - KO
      - NVDA
      - XOM
      - GS
      - HD
      - INTC
      - IBM
      - JNJ
      - JPM
      - MCD
      - MRK
      - MSFT
      - NKE
      - PFE
      - PG
      - RTX
      - TRV
      - UNH
      - VZ
      - V
      - WBA
      - WMT
      - DIS
    sse50:
      - "600028.SS"
      - "600030.SS"
      - "600031.SS"
      - "600036.SS"
      - "600048.SS"
      - "600050.SS"
      - "600150.SS"
      - "600276.SS"
      - "600309.SS"
      - "600406.SS"
      - "600519.SS"
      - "600690.SS"
      - "600760.SS"
      - "600809.SS"
      - "600887.SS"
      - "600900.SS"
      - "601088.SS"
      - "601166.SS"
      - "601318.SS"
      - "601328.SS"
      - "601398.SS"
      - "601600.SS"
      - "601601.SS"
      - "601628.SS"
      - "601668.SS"
      - "601857.SS"
      - "601888.SS"
      - "601899.SS"
      - "601919.SS"
      - "601988.SS"
    ftse100:
      - "RMV.L"
      - "IMI.L"
      - "ICG.L"
      - "PRU.L"
      - "AAL.L"
      - "KGF.L"
      - "DGE.L"
      - "PCT.L"
      - "FRES.L"
      - "UTG.L"
      - "SDR.L"
      - "WTB.L"
      - "HSX.L"
      - "LMP.L"
      - "VOD.L"
      - "HSBA.L"
      - "SGRO.L"
      - "IMB.L"
      - "MRO.L"
      - "BA.L"
      - "CNA.L"
      - "AV.L"
      - "TATE.L"
      - "BARC.L"
      - "BEZ.L"
      - "PHNX.L"
      - "AHT.L"
      - "BP.L"
      - "ANTO.L"
      - "RTO.L"

  comparisonStrategies:
    - "dow"
    - "sse50"
    - "ftse100"
  redownload: True
  start_date: "2009-01-01"
  period: "1D"
  base_seed: 9
  transaction_cost: 0.0002
  start_cash: 10000
  perturbation_noise: 0.01

agent:
  gamma: 0.99
  reward_function: "Standard Logarithmic Returns"
  actor_critic_hidden_state_size: 512
  ppo:
    gae_lambda: 0.98
    clip_param: 0.2
    batch_size: 48
    learning_rate: 0.0003
    fc1_n: 128
    fc2_n: 128
    feature_output_size: 128
    epochs: 4
    entropy_coef: 0.01
    actor_noise: 0
    norm_advantages: true
    use_entropy: true
    use_dirichlet: true
    log_concentration: false
    use_normals: false # likely requires softmax; dividing may not work for short selling
    learning_frequency: 48
    strategy: "PPOLSTM"
  td3:
    alpha: 0.001
    beta: 0.001
    tau: 0.005
    feature_output_size: 128
    batch_size: 100
    fc1_n: 512
    fc2_n: 384
    actor_noise: 0.01
    number_of_updates: 2
    target_noise: 0.01
    strategy: "TD3"

feature_extractors:
  lstm:
    default_hidden_size: 128
    return_hidden_state: False

hyperparameters:
  feature_output_sizes:
    - 32
    - 64
    - 128
    - 256
    - 512

evaluation:
  log_observations: false
  log_input_data: false

#argparse or something?
experiments:
  _common: &defaults
    dataType: "validation"
    benchmark: false
    comparisonStrat: null
    use_noise_eval: false
    for_learning_curve: false

  hyperparameter_tuning:
    <<: *defaults

  reward_testing:
    dataType: "testing"
    benchmark: null
    comparisonStrat: null
    use_noise_eval: false #possible comparison with perturbed?
    for_learning_curve: True
    source_folder: "main"

  random:
    <<: *defaults
    benchmark: true
    use_noise_eval: true

  nonRLComparisonStrategies:
    <<: *defaults
    dataType: "testing"

test:
  learning_curve_frequency: 500
